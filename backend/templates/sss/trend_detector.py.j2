# Trend Detector: {{ node_id }}
# Emit when {{ num_consecutive }} consecutive values are monotonic {{ direction }} (tolerance: {{ tolerance }})
# Uses TransformWithState with ListState for last N values

from pyspark.sql.streaming import StatefulProcessor, StatefulProcessorHandle
from pyspark.sql.types import StructType, StructField, DoubleType, LongType, StringType
import pandas as pd

class TrendDetectorProcessor(StatefulProcessor):
    def init(self, handle: StatefulProcessorHandle) -> None:
        self.handle = handle
        list_schema = StructType([StructField("value", DoubleType(), True)])
        self.values = handle.getListState("values", list_schema)

    def handleInputRows(self, key, rows, timerValues):
        n = {{ num_consecutive }}
        direction = "{{ direction }}"  # increase or decrease
        tolerance = {{ tolerance }}
        value_col = "{{ value_column }}"

        for pdf in rows:
            if not pdf.empty and value_col in pdf.columns:
                for _, row in pdf.iterrows():
                    try:
                        v = float(row[value_col])
                        self.values.append((v,))
                    except (TypeError, ValueError):
                        pass

        all_vals = [x[0] for x in list(self.values.get())]
        if len(all_vals) < n:
            return

        # Keep last n values
        last_n = all_vals[-n:]
        self.values.clear()
        for v in last_n:
            self.values.append((v,))

        # Check monotonic
        is_increasing = all(last_n[i] + tolerance >= last_n[i - 1] for i in range(1, n))
        is_decreasing = all(last_n[i] <= last_n[i - 1] + tolerance for i in range(1, n))

        if direction == "increase" and is_increasing:
            yield pd.DataFrame({
                "{{ key_column }}": [key],
                "direction": ["increase"],
                "values": [str(last_n)],
                "num_consecutive": [n],
            })
        elif direction == "decrease" and is_decreasing:
            yield pd.DataFrame({
                "{{ key_column }}": [key],
                "direction": ["decrease"],
                "values": [str(last_n)],
                "num_consecutive": [n],
            })

    def handleExpiredTimer(self, key, timerValues, expiredTimerInfo):
        pass

    def close(self) -> None:
        pass

output_schema = StructType([
    StructField("{{ key_column }}", StringType(), True),
    StructField("direction", StringType(), True),
    StructField("values", StringType(), True),
    StructField("num_consecutive", LongType(), True),
])

df_{{ node_id | replace("-", "_") }} = (
    {{ upstream_var }}
    .groupBy(F.col("{{ key_column }}"))
    .transformWithStateInPandas(
        statefulProcessor=TrendDetectorProcessor(),
        outputStructType=output_schema,
        outputMode="Append",
        timeMode="ProcessingTime",
    )
)
