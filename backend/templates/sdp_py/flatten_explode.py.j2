# Flatten-explode: {{ node_id }}

import dlt
from pyspark.sql import functions as F

@dlt.table(name="{{ node_id }}")
def {{ node_id }}():
    return (
        dlt.read_stream("{{ source_table }}")
        .select("*", F.explode("{{ array_column }}").alias("{{ alias }}"))
    )
